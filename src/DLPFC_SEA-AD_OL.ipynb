{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DLPFC SEA-AD Oligodendrocyte Analysis\n",
        "\n",
        "This notebook analyzes oligodendrocyte data from the SEA-AD dataset, specifically focusing on the dorsolateral prefrontal cortex (DLPFC) region and comparing different Braak stages.\n",
        "\n",
        "## Objectives:\n",
        "1. Load and inspect the OLIGO_DLPFC_SEA-AD.h5ad dataset\n",
        "2. Check data normalization status\n",
        "3. Filter for Braak stages: Reference, Braak 3, and Braak 6\n",
        "4. Perform standard Scanpy processing if needed\n",
        "5. Analyze cluster composition by Braak stage\n",
        "6. Perform differential gene expression analysis\n",
        "7. Visualize results with volcano plots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import scanpy as sc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure matplotlib for modern Jupyter notebook display\n",
        "# Use plt.rcParams instead of deprecated IPython.display.set_matplotlib_formats\n",
        "plt.rcParams['figure.autolayout'] = True  # Prevents label overlapping\n",
        "plt.rcParams['figure.dpi'] = 150  # Higher DPI for better resolution\n",
        "plt.rcParams['figure.figsize'] = (10, 6)  # Default figure size\n",
        "plt.rcParams['savefig.format'] = 'png'  # Default save format\n",
        "plt.rcParams['savefig.dpi'] = 300  # High resolution for saved figures\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['axes.titlesize'] = 14\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "plt.rcParams['xtick.labelsize'] = 10\n",
        "plt.rcParams['ytick.labelsize'] = 10\n",
        "plt.rcParams['legend.fontsize'] = 10\n",
        "\n",
        "# Set scanpy settings without using deprecated set_figure_params\n",
        "sc.settings.verbosity = 3  # verbosity level\n",
        "# Configure scanpy settings manually to avoid deprecated IPython function calls\n",
        "sc.settings._vector_friendly = False\n",
        "sc.settings.dpi = 150  # Match matplotlib DPI\n",
        "sc.settings.dpi_save = 300\n",
        "sc.settings.frameon = True\n",
        "sc.settings.fontsize = 12\n",
        "sc.settings.figsize = (10, 6)\n",
        "sc.settings.color_map = 'viridis'\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(\"Matplotlib and Scanpy configured for modern Jupyter display\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data path from environment variables\n",
        "data_path = os.getenv('DATA_PATH')\n",
        "if data_path is None:\n",
        "    raise ValueError(\"DATA_PATH not found in environment variables. Please check your .env file.\")\n",
        "\n",
        "# Construct the full path to the data file\n",
        "data_file_path = os.path.join(data_path, 'OLIGO_DLPFC_SEA-AD.h5ad')\n",
        "\n",
        "print(f\"Data path: {data_path}\")\n",
        "print(f\"Data file path: {data_file_path}\")\n",
        "\n",
        "# Check if file exists\n",
        "if not os.path.exists(data_file_path):\n",
        "    raise FileNotFoundError(f\"Data file not found at: {data_file_path}\")\n",
        "\n",
        "print(\"Data file found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the AnnData object\n",
        "print(\"Loading AnnData object...\")\n",
        "adata = sc.read_h5ad(data_file_path)\n",
        "\n",
        "print(f\"Dataset shape: {adata.shape}\")\n",
        "print(f\"Number of cells: {adata.n_obs}\")\n",
        "print(f\"Number of genes: {adata.n_vars}\")\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"\\nDataset info:\")\n",
        "print(f\"Obs (cells) columns: {list(adata.obs.columns)}\")\n",
        "print(f\"Var (genes) columns: {list(adata.var.columns)}\")\n",
        "\n",
        "# Check if there are any uns keys\n",
        "if adata.uns:\n",
        "    print(f\"Unstructured metadata keys: {list(adata.uns.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Normalization Check\n",
        "\n",
        "We need to check whether the data is normalized and if raw data is available for processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check data normalization status\n",
        "print(\"Checking data normalization status...\")\n",
        "\n",
        "# Check if raw data is available\n",
        "has_raw = adata.raw is not None\n",
        "print(f\"Raw data available: {has_raw}\")\n",
        "\n",
        "# Check the main data matrix properties\n",
        "print(f\"\\nMain data matrix:\")\n",
        "print(f\"  - Data type: {type(adata.X)}\")\n",
        "print(f\"  - Shape: {adata.X.shape}\")\n",
        "print(f\"  - Data type of values: {adata.X.dtype if hasattr(adata.X, 'dtype') else 'Unknown'}\")\n",
        "\n",
        "# Check for normalized data in layers\n",
        "print(f\"\\nAvailable layers: {list(adata.layers.keys())}\")\n",
        "\n",
        "# Check data distribution to infer normalization status\n",
        "sample_data = adata.X[:1000, :1000].toarray() if hasattr(adata.X, 'toarray') else adata.X[:1000, :1000]\n",
        "print(f\"\\nData statistics (sample of 1000x1000):\")\n",
        "print(f\"  - Min: {np.min(sample_data):.2f}\")\n",
        "print(f\"  - Max: {np.max(sample_data):.2f}\")\n",
        "print(f\"  - Mean: {np.mean(sample_data):.2f}\")\n",
        "print(f\"  - Median: {np.median(sample_data):.2f}\")\n",
        "\n",
        "# Determine if data appears to be normalized\n",
        "is_normalized = np.max(sample_data) < 50 and np.mean(sample_data) < 10\n",
        "print(f\"\\nData appears to be normalized: {is_normalized}\")\n",
        "\n",
        "# Store raw data if available and data is normalized\n",
        "if has_raw and is_normalized:\n",
        "    print(\"Raw count data is available and will be used for processing.\")\n",
        "    # Keep the current normalized data in X and raw in raw\n",
        "elif not has_raw and not is_normalized:\n",
        "    print(\"Data appears to be raw counts. Will proceed with normalization.\")\n",
        "    # This is raw count data, will need to normalize\n",
        "else:\n",
        "    print(\"Data status unclear. Will inspect further.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter Data for Braak Stages\n",
        "\n",
        "Filter the dataset to include only cells from Braak stages: Reference, Braak 3, and Braak 6.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check available Braak stage information\n",
        "print(\"Checking Braak stage information...\")\n",
        "\n",
        "# Look for Braak-related columns\n",
        "braak_columns = [col for col in adata.obs.columns if 'braak' in col.lower() or 'stage' in col.lower()]\n",
        "print(f\"Braak-related columns found: {braak_columns}\")\n",
        "\n",
        "# Display unique values in Braak-related columns\n",
        "for col in braak_columns:\n",
        "    unique_vals = adata.obs[col].unique()\n",
        "    print(f\"\\n{col} unique values:\")\n",
        "    print(unique_vals)\n",
        "    print(f\"Count per value:\")\n",
        "    print(adata.obs[col].value_counts())\n",
        "\n",
        "# Also check for any other potential grouping columns\n",
        "print(f\"\\nAll available obs columns:\")\n",
        "for col in adata.obs.columns:\n",
        "    print(f\"  - {col}: {len(adata.obs[col].unique())} unique values\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter data for specific Braak stages\n",
        "# Use the 'Braak stage' column specifically\n",
        "\n",
        "# Define the exact Braak stages we want to keep\n",
        "target_braak_stages = [\"Reference\", \"Braak III\", \"Braak VI\"]\n",
        "\n",
        "# Use the specific 'Braak stage' column\n",
        "braak_col = \"Braak stage\"\n",
        "filtered_adata = adata.copy()\n",
        "\n",
        "# Check if the 'Braak stage' column exists\n",
        "if braak_col in adata.obs.columns:\n",
        "    print(f\"Using column '{braak_col}' for filtering\")\n",
        "    \n",
        "    # Get unique values in the Braak stage column\n",
        "    unique_vals = adata.obs[braak_col].unique()\n",
        "    print(f\"Available values in {braak_col}: {unique_vals}\")\n",
        "    \n",
        "    # Find exact matches for our target stages\n",
        "    matching_values = []\n",
        "    for val in unique_vals:\n",
        "        if str(val) in target_braak_stages:\n",
        "            matching_values.append(val)\n",
        "    \n",
        "    if matching_values:\n",
        "        print(f\"Found matching values: {matching_values}\")\n",
        "        # Filter the data\n",
        "        mask = adata.obs[braak_col].isin(matching_values)\n",
        "        filtered_adata = adata[mask, :].copy()\n",
        "        print(f\"Filtered dataset shape: {filtered_adata.shape}\")\n",
        "        print(f\"Original dataset shape: {adata.shape}\")\n",
        "        print(f\"Cells removed: {adata.n_obs - filtered_adata.n_obs}\")\n",
        "        \n",
        "        # Show distribution of remaining Braak stages\n",
        "        print(f\"\\nDistribution after filtering:\")\n",
        "        print(filtered_adata.obs[braak_col].value_counts())\n",
        "    else:\n",
        "        print(\"No matching Braak stage values found. Keeping all data.\")\n",
        "        print(\"Available values:\", unique_vals)\n",
        "        print(\"Target values:\", target_braak_stages)\n",
        "else:\n",
        "    print(f\"Column '{braak_col}' not found in data.\")\n",
        "    print(\"Available Braak-related columns:\", braak_columns)\n",
        "    print(\"Available columns:\", list(adata.obs.columns))\n",
        "\n",
        "# Update adata to the filtered version\n",
        "adata = filtered_adata\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Standard Scanpy Processing\n",
        "\n",
        "If the data contains raw counts, perform standard Scanpy preprocessing steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform standard Scanpy processing if data appears to be raw counts\n",
        "if not is_normalized or (has_raw and not is_normalized):\n",
        "    print(\"Performing standard Scanpy preprocessing...\")\n",
        "    \n",
        "    # Store raw data if not already stored\n",
        "    if not has_raw:\n",
        "        print(\"Storing raw count data...\")\n",
        "        adata.raw = adata\n",
        "    \n",
        "    # Basic filtering\n",
        "    print(\"Calculating QC metrics...\")\n",
        "    sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True)\n",
        "    \n",
        "    # Filter genes and cells\n",
        "    print(\"Filtering genes and cells...\")\n",
        "    # Filter genes that are expressed in fewer than 3 cells\n",
        "    sc.pp.filter_genes(adata, min_cells=3)\n",
        "    \n",
        "    # Filter cells that have fewer than 200 genes expressed\n",
        "    sc.pp.filter_cells(adata, min_genes=200)\n",
        "    \n",
        "    # Remove cells with high mitochondrial gene expression\n",
        "    adata.var['mt'] = adata.var_names.str.startswith('MT-')\n",
        "    sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True)\n",
        "    \n",
        "    # Remove cells with >20% mitochondrial genes\n",
        "    adata = adata[adata.obs.pct_counts_mt < 20, :]\n",
        "    \n",
        "    print(f\"After filtering: {adata.shape}\")\n",
        "    \n",
        "    # Normalize and log-transform\n",
        "    print(\"Normalizing and log-transforming...\")\n",
        "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
        "    sc.pp.log1p(adata)\n",
        "    \n",
        "    # Find highly variable genes\n",
        "    print(\"Finding highly variable genes...\")\n",
        "    sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
        "    \n",
        "    # Keep only highly variable genes for downstream analysis\n",
        "    adata.raw = adata\n",
        "    adata = adata[:, adata.var.highly_variable]\n",
        "    \n",
        "    print(f\"After HVG filtering: {adata.shape}\")\n",
        "    \n",
        "else:\n",
        "    print(\"Data appears to be pre-processed. Skipping normalization steps.\")\n",
        "\n",
        "print(\"Preprocessing complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering Analysis\n",
        "\n",
        "Perform clustering and analyze cluster composition by Braak stage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform clustering analysis\n",
        "print(\"Performing clustering analysis...\")\n",
        "\n",
        "# Scale the data\n",
        "print(\"Scaling data...\")\n",
        "sc.pp.scale(adata, max_value=10)\n",
        "\n",
        "# Principal component analysis\n",
        "print(\"Performing PCA...\")\n",
        "sc.tl.pca(adata, svd_solver='arpack')\n",
        "\n",
        "# Compute neighborhood graph\n",
        "print(\"Computing neighborhood graph...\")\n",
        "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\n",
        "\n",
        "# Perform UMAP embedding\n",
        "print(\"Computing UMAP embedding...\")\n",
        "sc.tl.umap(adata)\n",
        "\n",
        "# Perform Leiden clustering\n",
        "print(\"Performing Leiden clustering...\")\n",
        "sc.tl.leiden(adata, resolution=0.5)\n",
        "\n",
        "# Check if clustering was successful\n",
        "if 'leiden' in adata.obs.columns:\n",
        "    n_clusters = len(adata.obs['leiden'].unique())\n",
        "    print(f\"Found {n_clusters} clusters\")\n",
        "    print(\"Cluster sizes:\")\n",
        "    print(adata.obs['leiden'].value_counts().sort_index())\n",
        "else:\n",
        "    print(\"Clustering failed - no 'leiden' column found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze cluster composition by Braak stage\n",
        "print(\"Analyzing cluster composition by Braak stage...\")\n",
        "\n",
        "if braak_col and 'leiden' in adata.obs.columns:\n",
        "    # Create a cross-tabulation\n",
        "    cluster_braak_crosstab = pd.crosstab(adata.obs['leiden'], adata.obs[braak_col])\n",
        "    print(\"\\nCluster composition by Braak stage:\")\n",
        "    print(cluster_braak_crosstab)\n",
        "    \n",
        "    # Calculate proportions\n",
        "    cluster_braak_prop = pd.crosstab(adata.obs['leiden'], adata.obs[braak_col], normalize='index')\n",
        "    print(\"\\nCluster composition by Braak stage (proportions):\")\n",
        "    print(cluster_braak_prop)\n",
        "    \n",
        "    # Visualize cluster composition\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    \n",
        "    # Absolute counts\n",
        "    cluster_braak_crosstab.plot(kind='bar', ax=axes[0], stacked=True)\n",
        "    axes[0].set_title('Cluster Composition by Braak Stage (Counts)')\n",
        "    axes[0].set_xlabel('Cluster')\n",
        "    axes[0].set_ylabel('Number of Cells')\n",
        "    axes[0].legend(title='Braak Stage', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    \n",
        "    # Proportions\n",
        "    cluster_braak_prop.plot(kind='bar', ax=axes[1], stacked=True)\n",
        "    axes[1].set_title('Cluster Composition by Braak Stage (Proportions)')\n",
        "    axes[1].set_xlabel('Cluster')\n",
        "    axes[1].set_ylabel('Proportion')\n",
        "    axes[1].legend(title='Braak Stage', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Statistical test for cluster composition differences\n",
        "    from scipy.stats import chi2_contingency\n",
        "    \n",
        "    chi2, p_value, dof, expected = chi2_contingency(cluster_braak_crosstab)\n",
        "    print(f\"\\nChi-square test for cluster composition differences:\")\n",
        "    print(f\"Chi-square statistic: {chi2:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4e}\")\n",
        "    print(f\"Degrees of freedom: {dof}\")\n",
        "    \n",
        "    if p_value < 0.05:\n",
        "        print(\"Significant difference in cluster composition between Braak stages (p < 0.05)\")\n",
        "    else:\n",
        "        print(\"No significant difference in cluster composition between Braak stages (p >= 0.05)\")\n",
        "\n",
        "else:\n",
        "    print(\"Cannot analyze cluster composition - missing Braak stage or cluster information\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Differential Gene Expression Analysis\n",
        "\n",
        "Perform differential gene expression analysis between Braak stages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform differential gene expression analysis\n",
        "print(\"Performing differential gene expression analysis...\")\n",
        "\n",
        "# Check if we have the necessary information\n",
        "if braak_col and adata.raw is not None:\n",
        "    print(f\"Using Braak stage column: {braak_col}\")\n",
        "    print(f\"Available Braak stages: {adata.obs[braak_col].unique()}\")\n",
        "    \n",
        "    # Get unique Braak stages\n",
        "    unique_braak_stages = adata.obs[braak_col].unique()\n",
        "    \n",
        "    # Perform pairwise comparisons\n",
        "    comparisons = []\n",
        "    \n",
        "    # Find Reference and Braak 3/6 for comparison\n",
        "    ref_stage = None\n",
        "    braak3_stage = None\n",
        "    braak6_stage = None\n",
        "    \n",
        "    for stage in unique_braak_stages:\n",
        "        stage_str = str(stage).lower()\n",
        "        if 'reference' in stage_str:\n",
        "            ref_stage = stage\n",
        "        elif 'braak' in stage_str and '3' in stage_str:\n",
        "            braak3_stage = stage\n",
        "        elif 'braak' in stage_str and '6' in stage_str:\n",
        "            braak6_stage = stage\n",
        "    \n",
        "    print(f\"Reference stage: {ref_stage}\")\n",
        "    print(f\"Braak 3 stage: {braak3_stage}\")\n",
        "    print(f\"Braak 6 stage: {braak6_stage}\")\n",
        "    \n",
        "    # Perform comparisons\n",
        "    if ref_stage and braak3_stage:\n",
        "        print(f\"\\nComparing {ref_stage} vs {braak3_stage}\")\n",
        "        sc.tl.rank_genes_groups(adata, braak_col, groups=[braak3_stage], reference=ref_stage, \n",
        "                               method='wilcoxon', use_raw=True)\n",
        "        comparisons.append(f\"{ref_stage}_vs_{braak3_stage}\")\n",
        "    \n",
        "    if braak3_stage and braak6_stage:\n",
        "        print(f\"\\nComparing {braak3_stage} vs {braak6_stage}\")\n",
        "        sc.tl.rank_genes_groups(adata, braak_col, groups=[braak6_stage], reference=braak3_stage, \n",
        "                               method='wilcoxon', use_raw=True)\n",
        "        comparisons.append(f\"{braak3_stage}_vs_{braak6_stage}\")\n",
        "    \n",
        "    print(f\"Completed {len(comparisons)} comparisons\")\n",
        "    \n",
        "else:\n",
        "    print(\"Cannot perform DEG analysis - missing Braak stage information or raw data\")\n",
        "    print(f\"Braak column: {braak_col}\")\n",
        "    print(f\"Raw data available: {adata.raw is not None}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Volcano Plot Visualization\n",
        "\n",
        "Create volcano plots to visualize the differential gene expression results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create volcano plots for differential gene expression results\n",
        "def create_volcano_plot(adata, comparison_name, pval_thresh=0.05, logfc_thresh=0.5):\n",
        "    \"\"\"Create a volcano plot for differential gene expression results\"\"\"\n",
        "    \n",
        "    # Get the results\n",
        "    result = adata.uns['rank_genes_groups']\n",
        "    groups = result['names'].dtype.names\n",
        "    \n",
        "    if len(groups) == 0:\n",
        "        print(f\"No groups found for comparison {comparison_name}\")\n",
        "        return\n",
        "    \n",
        "    # Get the first group (should be the comparison group)\n",
        "    group = groups[0]\n",
        "    \n",
        "    # Extract data\n",
        "    names = result['names'][group]\n",
        "    logfoldchanges = result['logfoldchanges'][group]\n",
        "    pvals = result['pvals'][group]\n",
        "    pvals_adj = result['pvals_adj'][group]\n",
        "    \n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'gene': names,\n",
        "        'logfc': logfoldchanges,\n",
        "        'pval': pvals,\n",
        "        'pval_adj': pvals_adj\n",
        "    })\n",
        "    \n",
        "    # Remove NaN values\n",
        "    df = df.dropna()\n",
        "    \n",
        "    # Calculate -log10(p-value)\n",
        "    df['neg_log10_pval'] = -np.log10(df['pval'])\n",
        "    \n",
        "    # Define significance\n",
        "    df['significant'] = (df['pval_adj'] < pval_thresh) & (np.abs(df['logfc']) > logfc_thresh)\n",
        "    df['upregulated'] = df['significant'] & (df['logfc'] > 0)\n",
        "    df['downregulated'] = df['significant'] & (df['logfc'] < 0)\n",
        "    \n",
        "    # Create volcano plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    \n",
        "    # Plot non-significant genes\n",
        "    ax.scatter(df[~df['significant']]['logfc'], \n",
        "               df[~df['significant']]['neg_log10_pval'], \n",
        "               c='gray', alpha=0.5, s=20, label='Not significant')\n",
        "    \n",
        "    # Plot upregulated genes\n",
        "    if df['upregulated'].sum() > 0:\n",
        "        ax.scatter(df[df['upregulated']]['logfc'], \n",
        "                   df[df['upregulated']]['neg_log10_pval'], \n",
        "                   c='red', alpha=0.7, s=30, label=f'Upregulated (n={df[\"upregulated\"].sum()})')\n",
        "    \n",
        "    # Plot downregulated genes\n",
        "    if df['downregulated'].sum() > 0:\n",
        "        ax.scatter(df[df['downregulated']]['logfc'], \n",
        "                   df[df['downregulated']]['neg_log10_pval'], \n",
        "                   c='blue', alpha=0.7, s=30, label=f'Downregulated (n={df[\"downregulated\"].sum()})')\n",
        "    \n",
        "    # Add threshold lines\n",
        "    ax.axhline(y=-np.log10(pval_thresh), color='black', linestyle='--', alpha=0.5)\n",
        "    ax.axvline(x=logfc_thresh, color='black', linestyle='--', alpha=0.5)\n",
        "    ax.axvline(x=-logfc_thresh, color='black', linestyle='--', alpha=0.5)\n",
        "    \n",
        "    # Labels and title\n",
        "    ax.set_xlabel('Log2 Fold Change')\n",
        "    ax.set_ylabel('-Log10 P-value')\n",
        "    ax.set_title(f'Volcano Plot: {comparison_name}')\n",
        "    ax.legend()\n",
        "    \n",
        "    # Add gene labels for top genes\n",
        "    top_genes = df.nlargest(5, 'neg_log10_pval')\n",
        "    for _, row in top_genes.iterrows():\n",
        "        ax.annotate(row['gene'], (row['logfc'], row['neg_log10_pval']), \n",
        "                   xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print summary statistics\n",
        "    print(f\"\\nSummary for {comparison_name}:\")\n",
        "    print(f\"Total genes tested: {len(df)}\")\n",
        "    print(f\"Significantly upregulated: {df['upregulated'].sum()}\")\n",
        "    print(f\"Significantly downregulated: {df['downregulated'].sum()}\")\n",
        "    print(f\"Top 5 upregulated genes:\")\n",
        "    top_up = df[df['upregulated']].nlargest(5, 'logfc')\n",
        "    for _, row in top_up.iterrows():\n",
        "        print(f\"  {row['gene']}: logFC={row['logfc']:.3f}, p-val={row['pval']:.2e}\")\n",
        "    \n",
        "    print(f\"Top 5 downregulated genes:\")\n",
        "    top_down = df[df['downregulated']].nsmallest(5, 'logfc')\n",
        "    for _, row in top_down.iterrows():\n",
        "        print(f\"  {row['gene']}: logFC={row['logfc']:.3f}, p-val={row['pval']:.2e}\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Create volcano plots for each comparison\n",
        "if 'rank_genes_groups' in adata.uns:\n",
        "    print(\"Creating volcano plots...\")\n",
        "    \n",
        "    # Create plots for each comparison\n",
        "    volcano_results = {}\n",
        "    \n",
        "    # Get the most recent comparison results\n",
        "    result = adata.uns['rank_genes_groups']\n",
        "    groups = result['names'].dtype.names\n",
        "    \n",
        "    for i, group in enumerate(groups):\n",
        "        comparison_name = f\"Comparison_{i+1}_{group}\"\n",
        "        print(f\"\\nCreating volcano plot for: {comparison_name}\")\n",
        "        \n",
        "        # Create a temporary adata with just this comparison\n",
        "        temp_adata = adata.copy()\n",
        "        temp_result = {\n",
        "            'names': result['names'][group:group+1],\n",
        "            'logfoldchanges': result['logfoldchanges'][group:group+1],\n",
        "            'pvals': result['pvals'][group:group+1],\n",
        "            'pvals_adj': result['pvals_adj'][group:group+1]\n",
        "        }\n",
        "        temp_adata.uns['rank_genes_groups'] = temp_result\n",
        "        \n",
        "        volcano_df = create_volcano_plot(temp_adata, comparison_name)\n",
        "        volcano_results[comparison_name] = volcano_df\n",
        "        \n",
        "else:\n",
        "    print(\"No differential gene expression results found for volcano plots\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results\n",
        "\n",
        "Create output folder and save all analysis results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directory\n",
        "output_dir = Path(\"../output\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "print(f\"Output directory: {output_dir.absolute()}\")\n",
        "\n",
        "# Save the processed AnnData object\n",
        "processed_data_path = output_dir / \"processed_DLPFC_SEA-AD_oligos.h5ad\"\n",
        "adata.write(processed_data_path)\n",
        "print(f\"Saved processed data to: {processed_data_path}\")\n",
        "\n",
        "# Save cluster composition results\n",
        "if braak_col and 'leiden' in adata.obs.columns:\n",
        "    cluster_braak_crosstab.to_csv(output_dir / \"cluster_braak_composition_counts.csv\")\n",
        "    cluster_braak_prop.to_csv(output_dir / \"cluster_braak_composition_proportions.csv\")\n",
        "    print(\"Saved cluster composition tables\")\n",
        "\n",
        "# Save differential gene expression results\n",
        "if 'rank_genes_groups' in adata.uns:\n",
        "    # Convert rank_genes_groups to DataFrame and save\n",
        "    result = adata.uns['rank_genes_groups']\n",
        "    \n",
        "    # Save each comparison separately\n",
        "    for group in result['names'].dtype.names:\n",
        "        comparison_name = f\"deg_results_{group}\"\n",
        "        \n",
        "        # Create DataFrame for this comparison\n",
        "        deg_df = pd.DataFrame({\n",
        "            'gene': result['names'][group],\n",
        "            'logfc': result['logfoldchanges'][group],\n",
        "            'pval': result['pvals'][group],\n",
        "            'pval_adj': result['pvals_adj'][group],\n",
        "            'scores': result['scores'][group] if 'scores' in result else None\n",
        "        })\n",
        "        \n",
        "        # Save to CSV\n",
        "        deg_path = output_dir / f\"{comparison_name}.csv\"\n",
        "        deg_df.to_csv(deg_path, index=False)\n",
        "        print(f\"Saved DEG results to: {deg_path}\")\n",
        "\n",
        "print(\"All results saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook has completed the following analyses:\n",
        "\n",
        "1. ✅ Loaded and inspected the OLIGO_DLPFC_SEA-AD.h5ad dataset\n",
        "2. ✅ Checked data normalization status and raw data availability\n",
        "3. ✅ Filtered data for Braak stages: Reference, Braak 3, and Braak 6\n",
        "4. ✅ Performed standard Scanpy processing (if raw counts detected)\n",
        "5. ✅ Analyzed cluster composition by Braak stage with statistical testing\n",
        "6. ✅ Performed differential gene expression analysis between Braak stages\n",
        "7. ✅ Created volcano plots for visualization\n",
        "8. ✅ Saved all results to the output folder\n",
        "\n",
        "### Key Files Generated:\n",
        "- `processed_DLPFC_SEA-AD_oligos.h5ad`: Processed AnnData object\n",
        "- `cluster_braak_composition_counts.csv`: Cluster composition counts\n",
        "- `cluster_braak_composition_proportions.csv`: Cluster composition proportions\n",
        "- `deg_results_[comparison].csv`: Differential gene expression results for each comparison\n",
        "\n",
        "### Next Steps:\n",
        "- Review the volcano plots for biologically relevant genes\n",
        "- Perform pathway enrichment analysis on significant DEGs\n",
        "- Validate findings with additional datasets or experimental approaches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
